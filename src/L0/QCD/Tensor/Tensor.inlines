namespace QCD
{
  inline std::complex< double > tr(Tensor const &tensor)
  {
    return tensor.trace();
  }

  inline std::complex< double > tr(hcTensor const &tensor)
  {
    return std::conj(tensor.dagger().trace());
  }

  inline Tensor::Tensor()
  {
    std::fill_n(d_data, 144, std::complex< double >(0.0, 0.0));
  }

  inline Tensor::Tensor(Tensor const &other)
  {
    std::copy(other.d_data, other.d_data + 144, d_data);
  }

  inline Tensor::Tensor(Spinor *data[12])
  {
    for (size_t ic=0; ic < 12; ic++)
      std::copy(reinterpret_cast< std::complex< double >* >(data[ic]),
                reinterpret_cast< std::complex< double >* >(data[ic]) + 12,
                d_data + ic*12);
  }

  inline Spinor &Tensor::operator()(size_t const idx)
  {
    return *(reinterpret_cast< Spinor * > (d_data + idx*12));
  }

  inline Spinor const &Tensor::operator()(size_t const idx) const
  {
    return *(reinterpret_cast< Spinor const * > (d_data + idx*12));
  }

  inline Tensor::Tensor(std::complex< double > *data)
  {
    std::copy(data, data + 144, d_data);
  }

  inline std::complex< double > &Tensor::operator[](size_t const idx)
  {
    return d_data[idx];
  }

  inline std::complex< double > const &Tensor::operator[](size_t const idx) const
  {
    return d_data[idx];
  }

  inline std::complex< double > &Tensor::operator()(size_t dirSink, size_t colSink, size_t dirSource, size_t colSource)
  {
    return d_data[dirSink * 36 + colSink * 12 + dirSource * 3 + colSource];
  }

  inline std::complex< double > const &Tensor::operator()(size_t dirSink, size_t colSink, size_t dirSource, size_t colSource) const
  {
    return d_data[dirSink * 36 + colSink * 12 + dirSource * 3 + colSource];
  }


  inline void Tensor::operator*=(std::complex< double > const &factor)
  {
    std::transform(d_data, d_data + 144, d_data,
                   std::bind2nd(std::multiplies< std::complex< double > >(), factor));
  }


  inline void Tensor::operator+=(Tensor const &other)
  {
    std::transform(d_data, d_data + 144, other.d_data, d_data,
                   std::plus< std::complex< double > >());
  }

  inline void Tensor::make_sequential(Tensor const &A, Tensor const &B)
  {
    reducedTensor rrA(A, Base::col_RED,   Base::col_RED);
    reducedTensor rgA(A, Base::col_RED,   Base::col_GREEN);
    reducedTensor rbA(A, Base::col_RED,   Base::col_BLUE);
    reducedTensor grA(A, Base::col_GREEN, Base::col_RED);
    reducedTensor ggA(A, Base::col_GREEN, Base::col_GREEN);
    reducedTensor gbA(A, Base::col_GREEN, Base::col_BLUE);
    reducedTensor brA(A, Base::col_BLUE,  Base::col_RED);
    reducedTensor bgA(A, Base::col_BLUE,  Base::col_GREEN);
    reducedTensor bbA(A, Base::col_BLUE,  Base::col_BLUE);

    reducedTensor rrB(B, Base::col_RED,   Base::col_RED);
    reducedTensor rgB(B, Base::col_RED,   Base::col_GREEN);
    reducedTensor rbB(B, Base::col_RED,   Base::col_BLUE);
    reducedTensor grB(B, Base::col_GREEN, Base::col_RED);
    reducedTensor gbB(B, Base::col_GREEN, Base::col_BLUE);
    reducedTensor ggB(B, Base::col_GREEN, Base::col_GREEN);
    reducedTensor brB(B, Base::col_BLUE,  Base::col_RED);
    reducedTensor bbB(B, Base::col_BLUE,  Base::col_BLUE);
    reducedTensor bgB(B, Base::col_BLUE,  Base::col_GREEN);

    // Non-zero combinations
    //  +(rrA, ggB, bbC), -(rrA, gbB, bgC), -(rrA, bgB, gbC), +(rrA, bbB, ggC)
    //  -(rgA, grB, bbC), +(rgA, gbB, brC), +(rgA, brB, gbC), -(rgA, bbB, grC)
    //  +(rbA, grB, bgC), -(rbA, ggB, brC), -(rbA, brB, ggC), +(rbA, bgB, grC)
    //  ---
    //  +(grA, bgB, rbC), -(grA, bbB, rgC), -(grA, rgB, bbC), +(grA, rbB, bgC)
    //  +(ggA, bbB, rrC), -(ggA, brB, rbC), -(ggA, rbB, brC), +(ggA, rrB, bbC)
    //  -(gbA, bgB, rrC), +(gbA, brB, rgC), +(gbA, rgB, brC), -(gbA, rrB, bgC)
    //  ---
    //  +(brA, rgB, gbC), -(brA, rbB, ggC), -(brA, ggB, rbC), +(brA, gbB, rgC)
    //  +(bgA, rbB, grC), -(bgA, rrB, gbC), -(bgA, gbB, rrC), +(bgA, grB, rbC)
    //  -(bbA, rgB, grC), +(bbA, rrB, ggC), +(bbA, ggB, rrC), -(bbA, grB, rgC)

    //experimentally only diagonal elements

    reducedTensor rrC  = ggA*bbB;
    rrC               -= gbA*bgB;
    rrC               -= bgA*gbB;
    rrC               += bbA*ggB;

    reducedTensor ggC  = rrA*bbB;
    ggC               -= rbA*brB;
    ggC               -= brA*rbB;
    ggC               += bbA*rrB;

    reducedTensor bbC  = rrA*ggB;
    bbC               -= rgA*grB;
    bbC               -= grA*rgB;
    bbC               += ggA*rrB;

/*
  constructor of reducedTensor:
  inline reducedTensor::reducedTensor(Tensor const &fullTensor, Base::ColourIndex const colour_src, Base::ColourIndex const colour_snk)
  {
    size_t index = 12*colour_src + colour_snk;
    d_data[ 0] = fullTensor.d_data[index     ];
    d_data[ 1] = fullTensor.d_data[index +   3];
    d_data[ 2] = fullTensor.d_data[index +   6];
    d_data[ 3] = fullTensor.d_data[index +   9];
    d_data[ 4] = fullTensor.d_data[index +  36];
    d_data[ 5] = fullTensor.d_data[index +  39];
    d_data[ 6] = fullTensor.d_data[index +  42];
    d_data[ 7] = fullTensor.d_data[index +  45];
    d_data[ 8] = fullTensor.d_data[index +  72];
    d_data[ 9] = fullTensor.d_data[index +  75];
    d_data[10] = fullTensor.d_data[index +  78];
    d_data[11] = fullTensor.d_data[index +  81];
    d_data[12] = fullTensor.d_data[index + 108];
    d_data[13] = fullTensor.d_data[index + 111];
    d_data[14] = fullTensor.d_data[index + 114];
    d_data[15] = fullTensor.d_data[index + 117];
  }*/

    size_t index = 12*Base::col_RED  + Base::col_RED;
    d_data[index      ] =  rrC.d_data[ 0];
    d_data[index +   3] =  rrC.d_data[ 1];
    d_data[index +   6] =  rrC.d_data[ 2];
    d_data[index +   9] =  rrC.d_data[ 3];
    d_data[index +  36] =  rrC.d_data[ 4];
    d_data[index +  39] =  rrC.d_data[ 5];
    d_data[index +  42] =  rrC.d_data[ 6];
    d_data[index +  45] =  rrC.d_data[ 7];
    d_data[index +  72] =  rrC.d_data[ 8];
    d_data[index +  75] =  rrC.d_data[ 9];
    d_data[index +  78] =  rrC.d_data[10];
    d_data[index +  81] =  rrC.d_data[11];
    d_data[index + 108] =  rrC.d_data[12];
    d_data[index + 111] =  rrC.d_data[13];
    d_data[index + 114] =  rrC.d_data[14];
    d_data[index + 117] =  rrC.d_data[15];

    index = 12*Base::col_GREEN  + Base::col_GREEN;
    d_data[index      ] =  ggC.d_data[ 0];
    d_data[index +   3] =  ggC.d_data[ 1];
    d_data[index +   6] =  ggC.d_data[ 2];
    d_data[index +   9] =  ggC.d_data[ 3];
    d_data[index +  36] =  ggC.d_data[ 4];
    d_data[index +  39] =  ggC.d_data[ 5];
    d_data[index +  42] =  ggC.d_data[ 6];
    d_data[index +  45] =  ggC.d_data[ 7];
    d_data[index +  72] =  ggC.d_data[ 8];
    d_data[index +  75] =  ggC.d_data[ 9];
    d_data[index +  78] =  ggC.d_data[10];
    d_data[index +  81] =  ggC.d_data[11];
    d_data[index + 108] =  ggC.d_data[12];
    d_data[index + 111] =  ggC.d_data[13];
    d_data[index + 114] =  ggC.d_data[14];
    d_data[index + 117] =  ggC.d_data[15];

    index = 12*Base::col_BLUE  + Base::col_BLUE;
    d_data[index      ] =  bbC.d_data[ 0];
    d_data[index +   3] =  bbC.d_data[ 1];
    d_data[index +   6] =  bbC.d_data[ 2];
    d_data[index +   9] =  bbC.d_data[ 3];
    d_data[index +  36] =  bbC.d_data[ 4];
    d_data[index +  39] =  bbC.d_data[ 5];
    d_data[index +  42] =  bbC.d_data[ 6];
    d_data[index +  45] =  bbC.d_data[ 7];
    d_data[index +  72] =  bbC.d_data[ 8];
    d_data[index +  75] =  bbC.d_data[ 9];
    d_data[index +  78] =  bbC.d_data[10];
    d_data[index +  81] =  bbC.d_data[11];
    d_data[index + 108] =  bbC.d_data[12];
    d_data[index + 111] =  bbC.d_data[13];
    d_data[index + 114] =  bbC.d_data[14];
    d_data[index + 117] =  bbC.d_data[15];

  }



  inline hcTensor Tensor::dagger() const
  {
    return hcTensor(*this);
  }

  inline void Tensor::conjugate()
  {
    for(size_t i=0; i < 144; i++)
      d_data[i] = conj(d_data[i]);
    // there must be a better way to do this using std::transform (the following example does not work):
    // std::transform(d_data, d_data + 144, d_data, std::ptr_fun(&conj));
  }


  inline void Tensor::transposeDirac()
  {
    // only swap non-diagonal SU3 (colour) vectors
    std::swap_ranges(d_data +   3, d_data +   6, d_data +  36);
    std::swap_ranges(d_data +   6, d_data +   9, d_data +  72);
    std::swap_ranges(d_data +   9, d_data +  12, d_data + 108);

    std::swap_ranges(d_data +  15, d_data +  18, d_data +  48);
    std::swap_ranges(d_data +  18, d_data +  21, d_data +  84);
    std::swap_ranges(d_data +  21, d_data +  24, d_data + 120);

    std::swap_ranges(d_data +  27, d_data +  30, d_data +  60);
    std::swap_ranges(d_data +  30, d_data +  33, d_data +  96);
    std::swap_ranges(d_data +  33, d_data +  36, d_data + 132);

    std::swap_ranges(d_data +  42, d_data +  45, d_data +  75);
    std::swap_ranges(d_data +  45, d_data +  48, d_data + 111);

    std::swap_ranges(d_data +  54, d_data +  57, d_data +  87);
    std::swap_ranges(d_data +  57, d_data +  60, d_data + 123);

    std::swap_ranges(d_data +  66, d_data +  69, d_data +  99);
    std::swap_ranges(d_data +  69, d_data +  72, d_data + 135);

    std::swap_ranges(d_data +  81, d_data +  84, d_data + 114);

    std::swap_ranges(d_data +  93, d_data +  96, d_data + 126);

    std::swap_ranges(d_data + 105, d_data + 108, d_data + 138);
  }

  inline void Tensor::transposeFull()
  {
    // only swap non-diagonal elements
    std::swap(*(d_data +   1), *(d_data +  12));
    std::swap(*(d_data +   2), *(d_data +  24));
    std::swap(*(d_data +   3), *(d_data +  36));
    std::swap(*(d_data +   4), *(d_data +  48));
    std::swap(*(d_data +   5), *(d_data +  60));
    std::swap(*(d_data +   6), *(d_data +  72));
    std::swap(*(d_data +   7), *(d_data +  84));
    std::swap(*(d_data +   8), *(d_data +  96));
    std::swap(*(d_data +   9), *(d_data + 108));
    std::swap(*(d_data +  10), *(d_data + 120));
    std::swap(*(d_data +  11), *(d_data + 132));
    // ---
    std::swap(*(d_data +  14), *(d_data +  25));
    std::swap(*(d_data +  15), *(d_data +  37));
    std::swap(*(d_data +  16), *(d_data +  49));
    std::swap(*(d_data +  17), *(d_data +  61));
    std::swap(*(d_data +  18), *(d_data +  73));
    std::swap(*(d_data +  19), *(d_data +  85));
    std::swap(*(d_data +  20), *(d_data +  97));
    std::swap(*(d_data +  21), *(d_data + 109));
    std::swap(*(d_data +  22), *(d_data + 121));
    std::swap(*(d_data +  23), *(d_data + 133));
    // ---
    std::swap(*(d_data +  27), *(d_data +  38));
    std::swap(*(d_data +  28), *(d_data +  50));
    std::swap(*(d_data +  29), *(d_data +  62));
    std::swap(*(d_data +  30), *(d_data +  74));
    std::swap(*(d_data +  31), *(d_data +  86));
    std::swap(*(d_data +  32), *(d_data +  98));
    std::swap(*(d_data +  33), *(d_data + 110));
    std::swap(*(d_data +  34), *(d_data + 122));
    std::swap(*(d_data +  35), *(d_data + 134));
    // ---
    std::swap(*(d_data +  40), *(d_data +  51));
    std::swap(*(d_data +  41), *(d_data +  63));
    std::swap(*(d_data +  42), *(d_data +  75));
    std::swap(*(d_data +  43), *(d_data +  87));
    std::swap(*(d_data +  44), *(d_data +  99));
    std::swap(*(d_data +  45), *(d_data + 111));
    std::swap(*(d_data +  46), *(d_data + 123));
    std::swap(*(d_data +  47), *(d_data + 135));
    // ---
    std::swap(*(d_data +  53), *(d_data +  64));
    std::swap(*(d_data +  54), *(d_data +  76));
    std::swap(*(d_data +  55), *(d_data +  88));
    std::swap(*(d_data +  56), *(d_data + 100));
    std::swap(*(d_data +  57), *(d_data + 112));
    std::swap(*(d_data +  58), *(d_data + 124));
    std::swap(*(d_data +  59), *(d_data + 136));
    // ---
    std::swap(*(d_data +  66), *(d_data +  77));
    std::swap(*(d_data +  67), *(d_data +  89));
    std::swap(*(d_data +  68), *(d_data + 101));
    std::swap(*(d_data +  69), *(d_data + 113));
    std::swap(*(d_data +  70), *(d_data + 125));
    std::swap(*(d_data +  71), *(d_data + 137));
    // ---
    std::swap(*(d_data +  79), *(d_data +  90));
    std::swap(*(d_data +  80), *(d_data + 102));
    std::swap(*(d_data +  81), *(d_data + 114));
    std::swap(*(d_data +  82), *(d_data + 126));
    std::swap(*(d_data +  83), *(d_data + 138));
    // ---
    std::swap(*(d_data +  92), *(d_data + 103));
    std::swap(*(d_data +  93), *(d_data + 115));
    std::swap(*(d_data +  94), *(d_data + 127));
    std::swap(*(d_data +  95), *(d_data + 139));
    // ---
    std::swap(*(d_data + 105), *(d_data + 116));
    std::swap(*(d_data + 106), *(d_data + 128));
    std::swap(*(d_data + 107), *(d_data + 140));
    // ---
    std::swap(*(d_data + 118), *(d_data + 129));
    std::swap(*(d_data + 119), *(d_data + 141));
    // ---
    std::swap(*(d_data + 131), *(d_data + 142));
  }



  inline std::complex< double > Tensor::trace() const
  {
    return d_data[0] + d_data[13] + d_data[26] + d_data[39] + d_data[52] + d_data[65]
           + d_data[78] + d_data[91] + d_data[104] + d_data[117] + d_data[130] + d_data[143];
  }

  inline size_t Tensor::size() const
  {
    return 144;
  }

  inline std::complex< double > Tensor::diff(Tensor const &other) const
  {
    std::complex< double > initial(0.0, 0.0);
    std::complex< double > final = std::accumulate(d_data, d_data+144, initial);
    final -= std::accumulate(other.d_data, other.d_data+144, initial);
    return final;
  }

  inline void Tensor::setToRandom()
  {
    std::generate_n(reinterpret_cast< double* >(d_data), 288, Base::Random::fastSymmetric);
  }

  inline void Tensor::setToRandom_Z4(Base::SourcePolarization const DState, Base::SourceColorState const CState)
  {
    std::fill_n(d_data, 144, std::complex< double >(0, 0));
    std::complex< double > tmp_data [12];
    std::generate_n(reinterpret_cast< double* >(tmp_data), 24, Base::Random::Z2);
    switch (DState)
    {
      // case Base::sou_UNPOLARIZED:
      case Base::sou_PARTLY_POLARIZED:
        switch (CState)
        {
          case Base::sou_GENERIC:
            std::copy(tmp_data, tmp_data + 12, d_data);
            std::copy(tmp_data, tmp_data + 12, d_data +  12);
            std::copy(tmp_data, tmp_data + 12, d_data +  24);
            std::copy(tmp_data, tmp_data + 12, d_data +  36);
            std::copy(tmp_data, tmp_data + 12, d_data +  48);
            std::copy(tmp_data, tmp_data + 12, d_data +  60);
            std::copy(tmp_data, tmp_data + 12, d_data +  72);
            std::copy(tmp_data, tmp_data + 12, d_data +  84);
            std::copy(tmp_data, tmp_data + 12, d_data +  96);
            std::copy(tmp_data, tmp_data + 12, d_data + 108);
            std::copy(tmp_data, tmp_data + 12, d_data + 120);
            std::copy(tmp_data, tmp_data + 12, d_data + 132);
            break;
          default:
          std::cerr << "This Base::SourceColorState is not implemented in Tensor::setToRandom_Z4()\n";
          std::cerr << "Aborting ..." << std::endl;
          exit(1);
        }
        break;
      case Base::sou_FULLY_POLARIZED:
        switch (CState)
        {
          // this is what is called spin diluted
          case Base::sou_GENERIC:
            std::copy(tmp_data,     tmp_data +  3, d_data);
            std::copy(tmp_data,     tmp_data +  3, d_data +  12);
            std::copy(tmp_data,     tmp_data +  3, d_data +  24);
            std::copy(tmp_data + 3, tmp_data +  6, d_data +  39);
            std::copy(tmp_data + 3, tmp_data +  6, d_data +  51);
            std::copy(tmp_data + 3, tmp_data +  6, d_data +  63);
            std::copy(tmp_data + 6, tmp_data +  9, d_data +  78);
            std::copy(tmp_data + 6, tmp_data +  9, d_data +  90);
            std::copy(tmp_data + 6, tmp_data +  9, d_data + 102);
            std::copy(tmp_data + 9, tmp_data + 12, d_data + 117);
            std::copy(tmp_data + 9, tmp_data + 12, d_data + 129);
            std::copy(tmp_data + 9, tmp_data + 12, d_data + 141);
            break;
          // this is what is called spin and color diluted
          case Base::sou_PURE:
            d_data[  0] = tmp_data[ 0];
            d_data[ 13] = tmp_data[ 1];
            d_data[ 26] = tmp_data[ 2];
            d_data[ 39] = tmp_data[ 3];
            d_data[ 52] = tmp_data[ 4];
            d_data[ 65] = tmp_data[ 5];
            d_data[ 78] = tmp_data[ 6];
            d_data[ 91] = tmp_data[ 7];
            d_data[104] = tmp_data[ 8];
            d_data[117] = tmp_data[ 9];
            d_data[130] = tmp_data[10];
            d_data[143] = tmp_data[11];
            break;
          default:
          std::cerr << "This Base::SourceColorState is not implemented in Tensor::setToRandom_Z4()\n";
          std::cerr << "Aborting ..." << std::endl;
          exit(1);
        }
        break;
      default:
      std::cerr << "This Base::SourcePolarization is not implemented in Tensor::setToRandom_Z4()\n";
      std::cerr << "Aborting ..." << std::endl;
      exit(1);
    }
  }

  inline Tensor::iterator Tensor::begin(Base::ColourIndex const idx, TensorColourStride const stride)
  {
    return iterator(*this, stride, 0);
  }


  inline Tensor::iterator Tensor::end(Base::ColourIndex const idx, TensorColourStride const stride)
  {
    return iterator(*this, stride, size());
  }


  inline Tensor::iterator Tensor::begin(Base::DiracIndex const idx, TensorDiracStride const stride)
  {
    return iterator(*this, stride, 0);
  }


  inline Tensor::iterator Tensor::end(Base::DiracIndex const idx, TensorDiracStride const stride)
  {
    return iterator(*this, stride ,size());
  }

  inline std::ostream &operator<<(std::ostream &out, Tensor const &tensor)
  {
    out <<  Spinor(tensor.d_data)       << Spinor(tensor.d_data +  12) << Spinor(tensor.d_data +  24);
    out <<  Spinor(tensor.d_data +  36) << Spinor(tensor.d_data +  48) << Spinor(tensor.d_data +  60);
    out <<  Spinor(tensor.d_data +  72) << Spinor(tensor.d_data +  84) << Spinor(tensor.d_data +  96);
    out <<  Spinor(tensor.d_data + 108) << Spinor(tensor.d_data + 120) << Spinor(tensor.d_data + 132) << std::endl;
    return out;
  }
}
