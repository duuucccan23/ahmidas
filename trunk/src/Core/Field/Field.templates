namespace Core
{
  template< typename Element, size_t L, size_t T >
  void Field< Element, L, T >::increaseIdx(short *idx) const
  {
    if ((++idx[idx_Z]) % d_grid.dim(idx_Z))
      return;
    if ((++idx[idx_Y]) % d_grid.dim(idx_Y))
      return;
    if ((++idx[idx_X]) % d_grid.dim(idx_X))
      return;
    ++idx[idx_T];
  }

  template< typename Element, size_t L, size_t T >
  void Field< Element, L, T >::decreaseIdx(short *idx) const
  {
    if (--idx[idx_Z] >= 0)
      return;
    idx[idx_Z] += d_grid.dim(idx_Z);
    if (--idx[idx_Y] >= 0)
      return;
    idx[idx_Y] += d_grid.dim(idx_Y);
    if (--idx[idx_X] >= 0)
      return;
    idx[idx_X] += d_grid.dim(idx_X);
    --idx[idx_T];
  }

  template< typename Element, size_t L, size_t T >
  Field< Element, L, T > &Field< Element, L, T >::shift(SpaceTimeIndex idx, Direction dir)
  {
    size_t dest = d_grid.neighbour(idx, dir);
    if (dest == d_grid.rank()) // We're just staying on the same node...
    {
      d_offsets[idx] += dir + d_grid.dim(idx);
      d_offsets[idx] %= d_grid.dim(idx); // Just move (and possibly wrap) the offset
      return *this;
    }

    int source = d_grid.neighbour(idx, dir == dir_UP ? dir_DOWN : dir_UP);

    // We use a buffered send, so we should be safe from deadlocks
    void *v_buffer = d_buffer;
    MPI::Attach_buffer(v_buffer, d_bufferSize);

    d_grid.grid().Bsend(d_field + (d_offsets[idx] * d_grid.surface(idx)), 1, d_surfaces[idx], dest, TAG_GAUGEFIELD);
    d_grid.grid().Recv(d_field + (d_offsets[idx] * d_grid.surface(idx)), 1, d_surfaces[idx], source, TAG_GAUGEFIELD);

    // Detaching the buffer provides an implicit synchronization mechanism, since we now know the buffer is cleared.
    void *v_bufp = &v_buffer;
    MPI::Detach_buffer(v_bufp);

    // Now all we need to do is shift the offset to reflect the new situation
    d_offsets[idx] += dir + d_grid.dim(idx);
    d_offsets[idx] %= d_grid.dim(idx);

    return *this;
  }

  template< typename Element, size_t L, size_t T >
  Field< Element, L, T >::Field(Grid< L, T > &grid, Element const &value)
    : d_grid(grid), d_buffer(new Element[d_grid.surface()]),
      d_field(new Element[d_grid.localVolume()])
  {
    std::fill(d_field, d_field + d_grid.localVolume(), value); // NOTE There may well be more efficient methods.
    std::fill(d_offsets, d_offsets + 4, 0);
    setSurfaces();
  }

  template< typename Element, size_t L, size_t T >
  Field< Element, L, T >::Field(Field< Element, L, T > const &other, Element const &value)
    : d_grid(other.d_grid),
      d_buffer(new Element[d_grid.surface()]),
      d_field(new Element[d_grid.localVolume()])
  {
    std::fill(d_offsets, d_offsets + 4, 0);
    std::fill(d_field, d_field + d_grid.localVolume(), value);
    std::copy(other.d_surfaces, other.d_surfaces + 4, d_surfaces);
  }

  template< typename Element, size_t L, size_t T >
  Field< Element, L, T >::Field(Field< Element, L, T > const &other)
    : d_grid(other.d_grid),
      d_buffer(new Element[d_grid.surface()]),
      d_field(new Element[d_grid.localVolume()])
  {
    std::copy(other.d_offsets, other.d_offsets + 4, d_offsets);
    std::copy(other.d_field, other.d_field + d_grid.localVolume(), d_field);
    std::copy(other.d_surfaces, other.d_surfaces + 4, d_surfaces);
  }

  template< typename Element, size_t L, size_t T >
  void Field< Element, L, T >::setSurfaces()
  {
    size_t const elSize = sizeof(Element) / sizeof(double);
    d_surfaces[idx_T] = MPI::DOUBLE.Create_vector(d_grid.localVolume() / d_grid.localVolume(),
                                                  d_grid.surface(idx_T) * elSize,
                                                  d_grid.localVolume() * elSize);
    d_surfaces[idx_T].Commit();

    d_surfaces[idx_X] = MPI::DOUBLE.Create_vector(d_grid.localVolume() / d_grid.surface(idx_T),
                                                  d_grid.surface(idx_X) * elSize,
                                                  d_grid.surface(idx_T) * elSize);
    d_surfaces[idx_X].Commit();

    d_surfaces[idx_Y] = MPI::DOUBLE.Create_vector(d_grid.localVolume() / d_grid.surface(idx_X),
                                                  d_grid.surface(idx_Y) * elSize,
                                                  d_grid.surface(idx_X) * elSize);
    d_surfaces[idx_Y].Commit();

    d_surfaces[idx_Z] = MPI::DOUBLE.Create_vector(d_grid.localVolume() / d_grid.surface(idx_Y),
                                                  d_grid.surface(idx_Z) * elSize,
                                                  d_grid.surface(idx_Y) * elSize);
    d_surfaces[idx_Z].Commit();

    for (size_t ctr = 0; ctr < 4; ++ctr)
      if (d_grid.dims()[ctr] != 1 && d_surfaces[ctr].Pack_size(1, d_grid.grid()) > d_bufferSize)
        d_bufferSize = d_surfaces[ctr].Pack_size(1, d_grid.grid());

    if (d_bufferSize != 0)
    {
      d_bufferSize += MPI_BSEND_OVERHEAD; // Nasty little source of segfaults...
      d_buffer = new Element[(d_bufferSize + elSize - 1) / elSize];
    }
  }
 
  std::complex< double > plus(std::complex< double > const &left, std::complex< double > const &right)
  {
    return (left + right);
  }
  
  template< typename Element, size_t L, size_t T >
  void Field< Element, L, T >::averageTimeSlice< std::complex< double > >(std::complex< double > *result)
  {
    void *v_buffer = d_buffer;
    MPI::Attach_buffer(v_buffer, d_bufferSize);
    
    MPI::Op operator_plus;
    operator_plus.Init(plus, true /* commutes */);

    for (size_t ctr = 0; ctr < d_grid.dim(idx_T); ++ctr)
      d_grid.timeSlice().Reduce(d_data + ctr * d_grid.localVolume(idx_T), 
                                result + d_grid.coord(idx_T) * d_grid.dim[idx_T] + ctr, 
                                d_surfaces[idx_T], MPI::DOUBLE_COMPLEX, operator_plus, 0);
       
    d_grid.grid().Barrier();
    
    if (timeSlice.Get_rank() == 0)
    {
      for (size_t ctr = 0; ctr < d_grid.dim(idx_T); ++ctr)
        result[d_grid.coord(idx_T) * d_grid.dim[idx_T] + ctr] /= d_grid.localVolume(idx_T);

      d_grid.grid().Gather(result + );
    }
    
    void *v_bufp = &v_buffer;
    MPI::Detach_buffer(v_bufp);
  }
}
